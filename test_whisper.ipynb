{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "6890495787d241aea5287f92957b42f1",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "VBox(children=(HTML(value='<center> <img\\nsrc=https://huggingface.co/front/assets/huggingface_logo-noborder.sv…"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "from huggingface_hub import notebook_login\n",
    "\n",
    "notebook_login()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Found cached dataset vivos (/home/tesla/.cache/huggingface/datasets/vivos/default/1.1.0/ab59078eb266c1a0ea856786ba56b5b8d56f29b42dfb37d92115cf81a7b1a5e0)\n",
      "Found cached dataset vivos (/home/tesla/.cache/huggingface/datasets/vivos/default/1.1.0/ab59078eb266c1a0ea856786ba56b5b8d56f29b42dfb37d92115cf81a7b1a5e0)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "DatasetDict({\n",
      "    train: Dataset({\n",
      "        features: ['speaker_id', 'path', 'audio', 'sentence'],\n",
      "        num_rows: 11660\n",
      "    })\n",
      "    test: Dataset({\n",
      "        features: ['speaker_id', 'path', 'audio', 'sentence'],\n",
      "        num_rows: 760\n",
      "    })\n",
      "})\n"
     ]
    }
   ],
   "source": [
    "from datasets import load_dataset, DatasetDict\n",
    "\n",
    "vivos = DatasetDict()\n",
    "\n",
    "vivos[\"train\"] = load_dataset(\"vivos\", split=\"train\", use_auth_token=True)\n",
    "vivos[\"test\"] = load_dataset(\"vivos\", split=\"test\", use_auth_token=True)\n",
    "\n",
    "print(vivos)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "vivos_clean = vivos.remove_columns([\"speaker_id\", \"path\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "from transformers import WhisperFeatureExtractor\n",
    "\n",
    "feature_extractor = WhisperFeatureExtractor.from_pretrained(\"openai/whisper-base\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "from transformers import WhisperTokenizer\n",
    "\n",
    "tokenizer = WhisperTokenizer.from_pretrained(\"openai/whisper-base\", language=\"Vietnamese\", task=\"transcribe\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Input:                 TÌNH YÊU THƯƠNG THẬT SỰ SỰ KIÊN TRÌ VÀ LÍ TƯỞNG TỐT ĐẸP NHẤT ĐỊNH SẼ CHIẾN THẮNG TẤT CẢ TRONG ĐÓ CÓ CẢ ĐÓI NGHÈO VÀ LẠC HẬU\n",
      "Decoded w/ special:    <|startoftranscript|><|vi|><|transcribe|><|notimestamps|>TÌNH YÊU THƯƠNG THẬT SỰ SỰ KIÊN TRÌ VÀ LÍ TƯỞNG TỐT ĐẸP NHẤT ĐỊNH SẼ CHIẾN THẮNG TẤT CẢ TRONG ĐÓ CÓ CẢ ĐÓI NGHÈO VÀ LẠC HẬU<|endoftext|>\n",
      "Decoded w/out special: TÌNH YÊU THƯƠNG THẬT SỰ SỰ KIÊN TRÌ VÀ LÍ TƯỞNG TỐT ĐẸP NHẤT ĐỊNH SẼ CHIẾN THẮNG TẤT CẢ TRONG ĐÓ CÓ CẢ ĐÓI NGHÈO VÀ LẠC HẬU\n",
      "Are equal:             True\n"
     ]
    }
   ],
   "source": [
    "input_str = vivos_clean[\"train\"][0][\"sentence\"]\n",
    "labels = tokenizer(input_str).input_ids\n",
    "decoded_with_special = tokenizer.decode(labels, skip_special_tokens=False)\n",
    "decoded_str = tokenizer.decode(labels, skip_special_tokens=True)\n",
    "\n",
    "print(f\"Input:                 {input_str}\")\n",
    "print(f\"Decoded w/ special:    {decoded_with_special}\")\n",
    "print(f\"Decoded w/out special: {decoded_str}\")\n",
    "print(f\"Are equal:             {input_str == decoded_str}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "from transformers import WhisperProcessor\n",
    "\n",
    "processor = WhisperProcessor.from_pretrained(\"openai/whisper-base\", language=\"Vietnamese\", task=\"transcribe\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "from datasets import Audio\n",
    "\n",
    "vivos_clean = vivos_clean.cast_column(\"audio\", Audio(sampling_rate=16000))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "def prepare_dataset(batch):\n",
    "    # load and resample audio data from 48 to 16kHz\n",
    "    audio = batch[\"audio\"]\n",
    "\n",
    "    # compute log-Mel input features from input audio array \n",
    "    batch[\"input_features\"] = feature_extractor(audio[\"array\"], sampling_rate=audio[\"sampling_rate\"]).input_features[0]\n",
    "\n",
    "    # encode target text to label ids \n",
    "    batch[\"labels\"] = tokenizer(batch[\"sentence\"]).input_ids\n",
    "    return batch\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Loading cached processed dataset at /home/tesla/.cache/huggingface/datasets/vivos/default/1.1.0/ab59078eb266c1a0ea856786ba56b5b8d56f29b42dfb37d92115cf81a7b1a5e0/cache-fc2a97bfe4f2483e_*_of_00004.arrow\n",
      "Loading cached processed dataset at /home/tesla/.cache/huggingface/datasets/vivos/default/1.1.0/ab59078eb266c1a0ea856786ba56b5b8d56f29b42dfb37d92115cf81a7b1a5e0/cache-b7f6150f2727bae7_*_of_00004.arrow\n"
     ]
    }
   ],
   "source": [
    "vivos_clean = vivos_clean.map(prepare_dataset, remove_columns=vivos_clean.column_names[\"train\"], num_proc=4)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "\n",
    "from dataclasses import dataclass\n",
    "from typing import Any, Dict, List, Union\n",
    "\n",
    "@dataclass\n",
    "class DataCollatorSpeechSeq2SeqWithPadding:\n",
    "    processor: Any\n",
    "\n",
    "    def __call__(self, features: List[Dict[str, Union[List[int], torch.Tensor]]]) -> Dict[str, torch.Tensor]:\n",
    "        # split inputs and labels since they have to be of different lengths and need different padding methods\n",
    "        # first treat the audio inputs by simply returning torch tensors\n",
    "        input_features = [{\"input_features\": feature[\"input_features\"]} for feature in features]\n",
    "        batch = self.processor.feature_extractor.pad(input_features, return_tensors=\"pt\")\n",
    "\n",
    "        # get the tokenized label sequences\n",
    "        label_features = [{\"input_ids\": feature[\"labels\"]} for feature in features]\n",
    "        # pad the labels to max length\n",
    "        labels_batch = self.processor.tokenizer.pad(label_features, return_tensors=\"pt\")\n",
    "\n",
    "        # replace padding with -100 to ignore loss correctly\n",
    "        labels = labels_batch[\"input_ids\"].masked_fill(labels_batch.attention_mask.ne(1), -100)\n",
    "\n",
    "        # if bos token is appended in previous tokenization step,\n",
    "        # cut bos token here as it's append later anyways\n",
    "        if (labels[:, 0] == self.processor.tokenizer.bos_token_id).all().cpu().item():\n",
    "            labels = labels[:, 1:]\n",
    "\n",
    "        batch[\"labels\"] = labels\n",
    "\n",
    "        return batch\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "data_collator = DataCollatorSpeechSeq2SeqWithPadding(processor=processor)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "\n",
    "os.environ[\"CUDA_VISIBLE_DEVICES\"] = \"0\"  "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Train\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "import evaluate\n",
    "\n",
    "metric = evaluate.load(\"wer\")\n",
    "\n",
    "\n",
    "def compute_metrics(pred):\n",
    "    pred_ids = pred.predictions\n",
    "    label_ids = pred.label_ids\n",
    "\n",
    "    # replace -100 with the pad_token_id\n",
    "    label_ids[label_ids == -100] = tokenizer.pad_token_id\n",
    "\n",
    "    # we do not want to group tokens when computing the metrics\n",
    "    pred_str = tokenizer.batch_decode(pred_ids, skip_special_tokens=True)\n",
    "    label_str = tokenizer.batch_decode(label_ids, skip_special_tokens=True)\n",
    "\n",
    "    wer = 100 * metric.compute(predictions=pred_str, references=label_str)\n",
    "\n",
    "    return {\"wer\": wer}\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "from transformers import WhisperForConditionalGeneration\n",
    "\n",
    "model = WhisperForConditionalGeneration.from_pretrained(\"openai/whisper-base\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "model.config.forced_decoder_ids = None\n",
    "model.config.suppress_tokens = []"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "from transformers import Seq2SeqTrainingArguments\n",
    "\n",
    "training_args = Seq2SeqTrainingArguments(\n",
    "    output_dir=\"./whisper-base-vi\",  # change to a repo name of your choice\n",
    "    per_device_train_batch_size=16,\n",
    "    gradient_accumulation_steps=1,  # increase by 2x for every 2x decrease in batch size\n",
    "    learning_rate=1e-5,\n",
    "    warmup_steps=500,\n",
    "    max_steps=4000,\n",
    "    gradient_checkpointing=True,\n",
    "    fp16=True,\n",
    "    evaluation_strategy=\"steps\",\n",
    "    per_device_eval_batch_size=8,\n",
    "    predict_with_generate=True,\n",
    "    generation_max_length=225,\n",
    "    save_steps=1000,\n",
    "    eval_steps=1000,\n",
    "    logging_steps=25,\n",
    "    report_to=[\"tensorboard\"],\n",
    "    load_best_model_at_end=True,\n",
    "    metric_for_best_model=\"wer\",\n",
    "    greater_is_better=False,\n",
    "    push_to_hub=True,\n",
    ")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/media/tesla/New Volume1/DEMO/DUY/Vietnamese_ASR/./whisper-base-vi is already a clone of https://huggingface.co/DuyTa/whisper-base-vi. Make sure you pull the latest changes with `repo.git_pull()`.\n"
     ]
    }
   ],
   "source": [
    "from transformers import Seq2SeqTrainer\n",
    "\n",
    "trainer = Seq2SeqTrainer(\n",
    "    args=training_args,\n",
    "    model=model,\n",
    "    train_dataset=vivos_clean[\"train\"],\n",
    "    eval_dataset=vivos_clean[\"test\"],\n",
    "    data_collator=data_collator,\n",
    "    compute_metrics=compute_metrics,\n",
    "    tokenizer=processor.feature_extractor,\n",
    ")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Device 0:\n",
      "  Currently allocated memory: 277.625 MB\n",
      "  Peak memory usage: 277.625 MB\n"
     ]
    }
   ],
   "source": [
    "import torch\n",
    "\n",
    "device_count = torch.cuda.device_count()\n",
    "\n",
    "for device in range(device_count):\n",
    "    torch.cuda.device(device)\n",
    "    allocated_memory = torch.cuda.memory_allocated(device)\n",
    "    peak_memory = torch.cuda.max_memory_allocated(device)\n",
    "    print(f\"Device {device}:\")\n",
    "    print(f\"  Currently allocated memory: {allocated_memory / 1024**2} MB\")\n",
    "    print(f\"  Peak memory usage: {peak_memory / 1024**2} MB\")\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Device 0:\n",
      "  Name: Tesla T4\n",
      "  Max Memory: 14966.375 MB\n"
     ]
    }
   ],
   "source": [
    "device_count = torch.cuda.device_count()\n",
    "\n",
    "for device in range(device_count):\n",
    "    properties = torch.cuda.get_device_properties(device)\n",
    "    print(f\"Device {device}:\")\n",
    "    print(f\"  Name: {properties.name}\")\n",
    "    print(f\"  Max Memory: {properties.total_memory / 1024**2} MB\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/tesla/miniconda3/envs/DUY/lib/python3.9/site-packages/transformers/optimization.py:411: FutureWarning: This implementation of AdamW is deprecated and will be removed in a future version. Use the PyTorch implementation torch.optim.AdamW instead, or set `no_deprecation_warning=True` to disable this warning\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "1d148188325d4e14bfe4fe0db09df58d",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/4000 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "`use_cache = True` is incompatible with gradient checkpointing. Setting `use_cache = False`...\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'loss': 3.3127, 'learning_rate': 4.2000000000000006e-07, 'epoch': 0.03}\n",
      "{'loss': 2.9406, 'learning_rate': 9.200000000000001e-07, 'epoch': 0.07}\n",
      "{'loss': 2.4168, 'learning_rate': 1.42e-06, 'epoch': 0.1}\n",
      "{'loss': 1.866, 'learning_rate': 1.9200000000000003e-06, 'epoch': 0.14}\n",
      "{'loss': 1.4583, 'learning_rate': 2.42e-06, 'epoch': 0.17}\n",
      "{'loss': 1.1891, 'learning_rate': 2.92e-06, 'epoch': 0.21}\n",
      "{'loss': 1.0304, 'learning_rate': 3.4200000000000007e-06, 'epoch': 0.24}\n",
      "{'loss': 0.8943, 'learning_rate': 3.920000000000001e-06, 'epoch': 0.27}\n",
      "{'loss': 0.7826, 'learning_rate': 4.42e-06, 'epoch': 0.31}\n",
      "{'loss': 0.733, 'learning_rate': 4.92e-06, 'epoch': 0.34}\n",
      "{'loss': 0.652, 'learning_rate': 5.420000000000001e-06, 'epoch': 0.38}\n",
      "{'loss': 0.6061, 'learning_rate': 5.92e-06, 'epoch': 0.41}\n",
      "{'loss': 0.5485, 'learning_rate': 6.42e-06, 'epoch': 0.45}\n",
      "{'loss': 0.5148, 'learning_rate': 6.92e-06, 'epoch': 0.48}\n",
      "{'loss': 0.4782, 'learning_rate': 7.420000000000001e-06, 'epoch': 0.51}\n",
      "{'loss': 0.4294, 'learning_rate': 7.92e-06, 'epoch': 0.55}\n",
      "{'loss': 0.4086, 'learning_rate': 8.42e-06, 'epoch': 0.58}\n",
      "{'loss': 0.4087, 'learning_rate': 8.920000000000001e-06, 'epoch': 0.62}\n",
      "{'loss': 0.3886, 'learning_rate': 9.42e-06, 'epoch': 0.65}\n",
      "{'loss': 0.3943, 'learning_rate': 9.920000000000002e-06, 'epoch': 0.69}\n",
      "{'loss': 0.3384, 'learning_rate': 9.940000000000001e-06, 'epoch': 0.72}\n",
      "{'loss': 0.3498, 'learning_rate': 9.86857142857143e-06, 'epoch': 0.75}\n",
      "{'loss': 0.3275, 'learning_rate': 9.797142857142858e-06, 'epoch': 0.79}\n",
      "{'loss': 0.3065, 'learning_rate': 9.725714285714287e-06, 'epoch': 0.82}\n",
      "{'loss': 0.304, 'learning_rate': 9.654285714285716e-06, 'epoch': 0.86}\n",
      "{'loss': 0.2806, 'learning_rate': 9.582857142857143e-06, 'epoch': 0.89}\n",
      "{'loss': 0.2866, 'learning_rate': 9.511428571428572e-06, 'epoch': 0.93}\n",
      "{'loss': 0.2786, 'learning_rate': 9.440000000000001e-06, 'epoch': 0.96}\n",
      "{'loss': 0.2857, 'learning_rate': 9.368571428571428e-06, 'epoch': 0.99}\n",
      "{'loss': 0.2507, 'learning_rate': 9.297142857142857e-06, 'epoch': 1.03}\n",
      "{'loss': 0.2509, 'learning_rate': 9.225714285714286e-06, 'epoch': 1.06}\n",
      "{'loss': 0.2412, 'learning_rate': 9.154285714285715e-06, 'epoch': 1.1}\n",
      "{'loss': 0.2314, 'learning_rate': 9.082857142857143e-06, 'epoch': 1.13}\n",
      "{'loss': 0.2139, 'learning_rate': 9.011428571428572e-06, 'epoch': 1.17}\n",
      "{'loss': 0.2154, 'learning_rate': 8.94e-06, 'epoch': 1.2}\n",
      "{'loss': 0.2219, 'learning_rate': 8.86857142857143e-06, 'epoch': 1.23}\n",
      "{'loss': 0.221, 'learning_rate': 8.797142857142857e-06, 'epoch': 1.27}\n",
      "{'loss': 0.2205, 'learning_rate': 8.725714285714286e-06, 'epoch': 1.3}\n",
      "{'loss': 0.2136, 'learning_rate': 8.654285714285715e-06, 'epoch': 1.34}\n",
      "{'loss': 0.2096, 'learning_rate': 8.582857142857144e-06, 'epoch': 1.37}\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "64ec5f5c0b6e412b9861e41f26bb1065",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/95 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'eval_loss': 0.29494285583496094, 'eval_wer': 32.038332038332044, 'eval_runtime': 216.8264, 'eval_samples_per_second': 3.505, 'eval_steps_per_second': 0.438, 'epoch': 1.37}\n",
      "{'loss': 0.2101, 'learning_rate': 8.511428571428571e-06, 'epoch': 1.41}\n",
      "{'loss': 0.194, 'learning_rate': 8.44e-06, 'epoch': 1.44}\n",
      "{'loss': 0.2033, 'learning_rate': 8.36857142857143e-06, 'epoch': 1.47}\n",
      "{'loss': 0.2314, 'learning_rate': 8.297142857142859e-06, 'epoch': 1.51}\n",
      "{'loss': 0.214, 'learning_rate': 8.225714285714288e-06, 'epoch': 1.54}\n",
      "{'loss': 0.1909, 'learning_rate': 8.154285714285715e-06, 'epoch': 1.58}\n",
      "{'loss': 0.2083, 'learning_rate': 8.082857142857144e-06, 'epoch': 1.61}\n",
      "{'loss': 0.2016, 'learning_rate': 8.011428571428573e-06, 'epoch': 1.65}\n",
      "{'loss': 0.1957, 'learning_rate': 7.94e-06, 'epoch': 1.68}\n",
      "{'loss': 0.1874, 'learning_rate': 7.86857142857143e-06, 'epoch': 1.71}\n",
      "{'loss': 0.1851, 'learning_rate': 7.797142857142858e-06, 'epoch': 1.75}\n",
      "{'loss': 0.1925, 'learning_rate': 7.725714285714286e-06, 'epoch': 1.78}\n",
      "{'loss': 0.1838, 'learning_rate': 7.654285714285715e-06, 'epoch': 1.82}\n",
      "{'loss': 0.1871, 'learning_rate': 7.5828571428571444e-06, 'epoch': 1.85}\n",
      "{'loss': 0.1874, 'learning_rate': 7.511428571428572e-06, 'epoch': 1.89}\n",
      "{'loss': 0.1907, 'learning_rate': 7.440000000000001e-06, 'epoch': 1.92}\n",
      "{'loss': 0.1755, 'learning_rate': 7.36857142857143e-06, 'epoch': 1.95}\n",
      "{'loss': 0.1891, 'learning_rate': 7.297142857142858e-06, 'epoch': 1.99}\n",
      "{'loss': 0.1563, 'learning_rate': 7.225714285714286e-06, 'epoch': 2.02}\n",
      "{'loss': 0.1418, 'learning_rate': 7.154285714285715e-06, 'epoch': 2.06}\n",
      "{'loss': 0.1348, 'learning_rate': 7.082857142857143e-06, 'epoch': 2.09}\n",
      "{'loss': 0.1388, 'learning_rate': 7.011428571428572e-06, 'epoch': 2.13}\n",
      "{'loss': 0.1424, 'learning_rate': 6.9400000000000005e-06, 'epoch': 2.16}\n",
      "{'loss': 0.1515, 'learning_rate': 6.868571428571429e-06, 'epoch': 2.19}\n",
      "{'loss': 0.1347, 'learning_rate': 6.797142857142858e-06, 'epoch': 2.23}\n",
      "{'loss': 0.1372, 'learning_rate': 6.725714285714287e-06, 'epoch': 2.26}\n",
      "{'loss': 0.1336, 'learning_rate': 6.654285714285716e-06, 'epoch': 2.3}\n",
      "{'loss': 0.1298, 'learning_rate': 6.582857142857143e-06, 'epoch': 2.33}\n",
      "{'loss': 0.1435, 'learning_rate': 6.511428571428572e-06, 'epoch': 2.37}\n",
      "{'loss': 0.1258, 'learning_rate': 6.440000000000001e-06, 'epoch': 2.4}\n",
      "{'loss': 0.1308, 'learning_rate': 6.368571428571429e-06, 'epoch': 2.43}\n",
      "{'loss': 0.1325, 'learning_rate': 6.297142857142857e-06, 'epoch': 2.47}\n",
      "{'loss': 0.1391, 'learning_rate': 6.225714285714286e-06, 'epoch': 2.5}\n",
      "{'loss': 0.1393, 'learning_rate': 6.1542857142857145e-06, 'epoch': 2.54}\n",
      "{'loss': 0.1445, 'learning_rate': 6.0828571428571435e-06, 'epoch': 2.57}\n",
      "{'loss': 0.1237, 'learning_rate': 6.011428571428572e-06, 'epoch': 2.61}\n",
      "{'loss': 0.1432, 'learning_rate': 5.94e-06, 'epoch': 2.64}\n",
      "{'loss': 0.131, 'learning_rate': 5.868571428571429e-06, 'epoch': 2.67}\n",
      "{'loss': 0.1225, 'learning_rate': 5.797142857142858e-06, 'epoch': 2.71}\n",
      "{'loss': 0.1205, 'learning_rate': 5.725714285714287e-06, 'epoch': 2.74}\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "ec7d8639801a469bae4dbb07e236a536",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/95 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'eval_loss': 0.25480595231056213, 'eval_wer': 26.85832685832686, 'eval_runtime': 213.9548, 'eval_samples_per_second': 3.552, 'eval_steps_per_second': 0.444, 'epoch': 2.74}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Several commits (2) will be pushed upstream.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'loss': 0.1212, 'learning_rate': 5.654285714285714e-06, 'epoch': 2.78}\n",
      "{'loss': 0.1435, 'learning_rate': 5.582857142857143e-06, 'epoch': 2.81}\n",
      "{'loss': 0.1351, 'learning_rate': 5.511428571428572e-06, 'epoch': 2.85}\n",
      "{'loss': 0.128, 'learning_rate': 5.4400000000000004e-06, 'epoch': 2.88}\n",
      "{'loss': 0.1225, 'learning_rate': 5.368571428571429e-06, 'epoch': 2.91}\n",
      "{'loss': 0.1394, 'learning_rate': 5.297142857142858e-06, 'epoch': 2.95}\n",
      "{'loss': 0.13, 'learning_rate': 5.225714285714286e-06, 'epoch': 2.98}\n",
      "{'loss': 0.1185, 'learning_rate': 5.154285714285715e-06, 'epoch': 3.02}\n",
      "{'loss': 0.0865, 'learning_rate': 5.082857142857144e-06, 'epoch': 3.05}\n",
      "{'loss': 0.1001, 'learning_rate': 5.011428571428571e-06, 'epoch': 3.09}\n",
      "{'loss': 0.0945, 'learning_rate': 4.94e-06, 'epoch': 3.12}\n",
      "{'loss': 0.0959, 'learning_rate': 4.868571428571429e-06, 'epoch': 3.16}\n",
      "{'loss': 0.0893, 'learning_rate': 4.797142857142857e-06, 'epoch': 3.19}\n",
      "{'loss': 0.0925, 'learning_rate': 4.725714285714286e-06, 'epoch': 3.22}\n",
      "{'loss': 0.0956, 'learning_rate': 4.6542857142857145e-06, 'epoch': 3.26}\n",
      "{'loss': 0.0948, 'learning_rate': 4.5828571428571435e-06, 'epoch': 3.29}\n",
      "{'loss': 0.0996, 'learning_rate': 4.511428571428572e-06, 'epoch': 3.33}\n",
      "{'loss': 0.1018, 'learning_rate': 4.440000000000001e-06, 'epoch': 3.36}\n",
      "{'loss': 0.1036, 'learning_rate': 4.368571428571429e-06, 'epoch': 3.4}\n",
      "{'loss': 0.098, 'learning_rate': 4.297142857142858e-06, 'epoch': 3.43}\n",
      "{'loss': 0.1095, 'learning_rate': 4.225714285714286e-06, 'epoch': 3.46}\n",
      "{'loss': 0.1052, 'learning_rate': 4.154285714285714e-06, 'epoch': 3.5}\n",
      "{'loss': 0.0943, 'learning_rate': 4.082857142857143e-06, 'epoch': 3.53}\n",
      "{'loss': 0.1072, 'learning_rate': 4.011428571428571e-06, 'epoch': 3.57}\n",
      "{'loss': 0.0962, 'learning_rate': 3.94e-06, 'epoch': 3.6}\n",
      "{'loss': 0.1079, 'learning_rate': 3.8685714285714286e-06, 'epoch': 3.64}\n",
      "{'loss': 0.1023, 'learning_rate': 3.7971428571428576e-06, 'epoch': 3.67}\n",
      "{'loss': 0.0926, 'learning_rate': 3.7257142857142857e-06, 'epoch': 3.7}\n",
      "{'loss': 0.1038, 'learning_rate': 3.6542857142857148e-06, 'epoch': 3.74}\n",
      "{'loss': 0.0893, 'learning_rate': 3.582857142857143e-06, 'epoch': 3.77}\n",
      "{'loss': 0.0927, 'learning_rate': 3.511428571428572e-06, 'epoch': 3.81}\n",
      "{'loss': 0.0961, 'learning_rate': 3.44e-06, 'epoch': 3.84}\n",
      "{'loss': 0.0961, 'learning_rate': 3.3685714285714287e-06, 'epoch': 3.88}\n",
      "{'loss': 0.0961, 'learning_rate': 3.2971428571428577e-06, 'epoch': 3.91}\n",
      "{'loss': 0.1003, 'learning_rate': 3.225714285714286e-06, 'epoch': 3.94}\n",
      "{'loss': 0.0895, 'learning_rate': 3.154285714285715e-06, 'epoch': 3.98}\n",
      "{'loss': 0.0898, 'learning_rate': 3.082857142857143e-06, 'epoch': 4.01}\n",
      "{'loss': 0.0705, 'learning_rate': 3.0114285714285716e-06, 'epoch': 4.05}\n",
      "{'loss': 0.0717, 'learning_rate': 2.9400000000000002e-06, 'epoch': 4.08}\n",
      "{'loss': 0.0767, 'learning_rate': 2.868571428571429e-06, 'epoch': 4.12}\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "023f14af2df24f9ab0bda6bd162fcfb1",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/95 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'eval_loss': 0.254891961812973, 'eval_wer': 25.343175343175346, 'eval_runtime': 212.1705, 'eval_samples_per_second': 3.582, 'eval_steps_per_second': 0.448, 'epoch': 4.12}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Several commits (3) will be pushed upstream.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'loss': 0.0785, 'learning_rate': 2.797142857142857e-06, 'epoch': 4.15}\n",
      "{'loss': 0.0732, 'learning_rate': 2.725714285714286e-06, 'epoch': 4.18}\n",
      "{'loss': 0.0749, 'learning_rate': 2.654285714285714e-06, 'epoch': 4.22}\n",
      "{'loss': 0.0742, 'learning_rate': 2.582857142857143e-06, 'epoch': 4.25}\n",
      "{'loss': 0.0766, 'learning_rate': 2.5114285714285718e-06, 'epoch': 4.29}\n",
      "{'loss': 0.0746, 'learning_rate': 2.4400000000000004e-06, 'epoch': 4.32}\n",
      "{'loss': 0.08, 'learning_rate': 2.3685714285714285e-06, 'epoch': 4.36}\n",
      "{'loss': 0.0778, 'learning_rate': 2.297142857142857e-06, 'epoch': 4.39}\n",
      "{'loss': 0.0677, 'learning_rate': 2.2257142857142857e-06, 'epoch': 4.42}\n",
      "{'loss': 0.0818, 'learning_rate': 2.1542857142857147e-06, 'epoch': 4.46}\n",
      "{'loss': 0.0733, 'learning_rate': 2.0828571428571433e-06, 'epoch': 4.49}\n",
      "{'loss': 0.0807, 'learning_rate': 2.0114285714285715e-06, 'epoch': 4.53}\n",
      "{'loss': 0.0811, 'learning_rate': 1.94e-06, 'epoch': 4.56}\n",
      "{'loss': 0.0671, 'learning_rate': 1.8685714285714289e-06, 'epoch': 4.6}\n",
      "{'loss': 0.0745, 'learning_rate': 1.7971428571428572e-06, 'epoch': 4.63}\n",
      "{'loss': 0.0797, 'learning_rate': 1.7257142857142858e-06, 'epoch': 4.66}\n",
      "{'loss': 0.0709, 'learning_rate': 1.6542857142857144e-06, 'epoch': 4.7}\n",
      "{'loss': 0.0699, 'learning_rate': 1.582857142857143e-06, 'epoch': 4.73}\n",
      "{'loss': 0.0734, 'learning_rate': 1.5114285714285714e-06, 'epoch': 4.77}\n",
      "{'loss': 0.0684, 'learning_rate': 1.44e-06, 'epoch': 4.8}\n",
      "{'loss': 0.0841, 'learning_rate': 1.3685714285714286e-06, 'epoch': 4.84}\n",
      "{'loss': 0.0684, 'learning_rate': 1.2971428571428574e-06, 'epoch': 4.87}\n",
      "{'loss': 0.0808, 'learning_rate': 1.2257142857142857e-06, 'epoch': 4.9}\n",
      "{'loss': 0.0761, 'learning_rate': 1.1542857142857143e-06, 'epoch': 4.94}\n",
      "{'loss': 0.0695, 'learning_rate': 1.082857142857143e-06, 'epoch': 4.97}\n",
      "{'loss': 0.0718, 'learning_rate': 1.0114285714285715e-06, 'epoch': 5.01}\n",
      "{'loss': 0.06, 'learning_rate': 9.400000000000001e-07, 'epoch': 5.04}\n",
      "{'loss': 0.0569, 'learning_rate': 8.685714285714286e-07, 'epoch': 5.08}\n",
      "{'loss': 0.0655, 'learning_rate': 7.971428571428572e-07, 'epoch': 5.11}\n",
      "{'loss': 0.0636, 'learning_rate': 7.257142857142857e-07, 'epoch': 5.14}\n",
      "{'loss': 0.0556, 'learning_rate': 6.542857142857144e-07, 'epoch': 5.18}\n",
      "{'loss': 0.0601, 'learning_rate': 5.82857142857143e-07, 'epoch': 5.21}\n",
      "{'loss': 0.058, 'learning_rate': 5.114285714285714e-07, 'epoch': 5.25}\n",
      "{'loss': 0.0567, 'learning_rate': 4.4e-07, 'epoch': 5.28}\n",
      "{'loss': 0.0698, 'learning_rate': 3.685714285714286e-07, 'epoch': 5.32}\n",
      "{'loss': 0.0633, 'learning_rate': 2.9714285714285715e-07, 'epoch': 5.35}\n",
      "{'loss': 0.0679, 'learning_rate': 2.2571428571428574e-07, 'epoch': 5.38}\n",
      "{'loss': 0.06, 'learning_rate': 1.542857142857143e-07, 'epoch': 5.42}\n",
      "{'loss': 0.0643, 'learning_rate': 8.285714285714285e-08, 'epoch': 5.45}\n",
      "{'loss': 0.0532, 'learning_rate': 1.142857142857143e-08, 'epoch': 5.49}\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "f408a9767a2f44d4b324f18aed8b00a5",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/95 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'eval_loss': 0.2565304934978485, 'eval_wer': 25.058275058275058, 'eval_runtime': 212.5224, 'eval_samples_per_second': 3.576, 'eval_steps_per_second': 0.447, 'epoch': 5.49}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Several commits (4) will be pushed upstream.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'train_runtime': 12408.1607, 'train_samples_per_second': 5.158, 'train_steps_per_second': 0.322, 'train_loss': 0.25067593112587927, 'epoch': 5.49}\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "TrainOutput(global_step=4000, training_loss=0.25067593112587927, metrics={'train_runtime': 12408.1607, 'train_samples_per_second': 5.158, 'train_steps_per_second': 0.322, 'train_loss': 0.25067593112587927, 'epoch': 5.49})"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "trainer.train()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "kwargs = {\n",
    "    \"dataset_tags\": \"vivos\",\n",
    "    \"dataset\": \"Vivos\",  # a 'pretty' name for the training dataset\n",
    "    \"language\": \"Vietnamese\",\n",
    "    \"model_name\": \"Whisper Base Vi - Duy Ta\",  # a 'pretty' name for your model\n",
    "    \"finetuned_from\": \"openai/whisper-base\",\n",
    "    \"tasks\": \"automatic-speech-recognition\",\n",
    "    \"tags\": \"hf-asr-leaderboard\",\n",
    "}\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Several commits (5) will be pushed upstream.\n",
      "The progress bars may be unreliable.\n",
      "batch response: Authorization error.\n",
      "error: failed to push some refs to 'https://huggingface.co/DuyTa/whisper-base-vi'\n",
      "\n"
     ]
    },
    {
     "ename": "OSError",
     "evalue": "batch response: Authorization error.\nerror: failed to push some refs to 'https://huggingface.co/DuyTa/whisper-base-vi'\n",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mCalledProcessError\u001b[0m                        Traceback (most recent call last)",
      "File \u001b[0;32m~/miniconda3/envs/DUY/lib/python3.9/site-packages/huggingface_hub/repository.py:1099\u001b[0m, in \u001b[0;36mRepository.git_push\u001b[0;34m(self, upstream, blocking, auto_lfs_prune)\u001b[0m\n\u001b[1;32m   1098\u001b[0m             \u001b[39mif\u001b[39;00m return_code:\n\u001b[0;32m-> 1099\u001b[0m                 \u001b[39mraise\u001b[39;00m subprocess\u001b[39m.\u001b[39mCalledProcessError(return_code, process\u001b[39m.\u001b[39margs, output\u001b[39m=\u001b[39mstdout, stderr\u001b[39m=\u001b[39mstderr)\n\u001b[1;32m   1101\u001b[0m \u001b[39mexcept\u001b[39;00m subprocess\u001b[39m.\u001b[39mCalledProcessError \u001b[39mas\u001b[39;00m exc:\n",
      "\u001b[0;31mCalledProcessError\u001b[0m: Command '['git', 'push', '--set-upstream', 'origin', 'main']' returned non-zero exit status 1.",
      "\nDuring handling of the above exception, another exception occurred:\n",
      "\u001b[0;31mOSError\u001b[0m                                   Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[23], line 1\u001b[0m\n\u001b[0;32m----> 1\u001b[0m trainer\u001b[39m.\u001b[39;49mpush_to_hub(\u001b[39m*\u001b[39;49m\u001b[39m*\u001b[39;49mkwargs)\n",
      "File \u001b[0;32m~/miniconda3/envs/DUY/lib/python3.9/site-packages/transformers/trainer.py:3609\u001b[0m, in \u001b[0;36mTrainer.push_to_hub\u001b[0;34m(self, commit_message, blocking, **kwargs)\u001b[0m\n\u001b[1;32m   3606\u001b[0m     \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mpush_in_progress\u001b[39m.\u001b[39m_process\u001b[39m.\u001b[39mkill()\n\u001b[1;32m   3607\u001b[0m     \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mpush_in_progress \u001b[39m=\u001b[39m \u001b[39mNone\u001b[39;00m\n\u001b[0;32m-> 3609\u001b[0m git_head_commit_url \u001b[39m=\u001b[39m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mrepo\u001b[39m.\u001b[39;49mpush_to_hub(\n\u001b[1;32m   3610\u001b[0m     commit_message\u001b[39m=\u001b[39;49mcommit_message, blocking\u001b[39m=\u001b[39;49mblocking, auto_lfs_prune\u001b[39m=\u001b[39;49m\u001b[39mTrue\u001b[39;49;00m\n\u001b[1;32m   3611\u001b[0m )\n\u001b[1;32m   3612\u001b[0m \u001b[39m# push separately the model card to be independant from the rest of the model\u001b[39;00m\n\u001b[1;32m   3613\u001b[0m \u001b[39mif\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39margs\u001b[39m.\u001b[39mshould_save:\n",
      "File \u001b[0;32m~/miniconda3/envs/DUY/lib/python3.9/site-packages/huggingface_hub/repository.py:1307\u001b[0m, in \u001b[0;36mRepository.push_to_hub\u001b[0;34m(self, commit_message, blocking, clean_ok, auto_lfs_prune)\u001b[0m\n\u001b[1;32m   1305\u001b[0m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mgit_add(auto_lfs_track\u001b[39m=\u001b[39m\u001b[39mTrue\u001b[39;00m)\n\u001b[1;32m   1306\u001b[0m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mgit_commit(commit_message)\n\u001b[0;32m-> 1307\u001b[0m \u001b[39mreturn\u001b[39;00m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mgit_push(\n\u001b[1;32m   1308\u001b[0m     upstream\u001b[39m=\u001b[39;49m\u001b[39mf\u001b[39;49m\u001b[39m\"\u001b[39;49m\u001b[39morigin \u001b[39;49m\u001b[39m{\u001b[39;49;00m\u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mcurrent_branch\u001b[39m}\u001b[39;49;00m\u001b[39m\"\u001b[39;49m,\n\u001b[1;32m   1309\u001b[0m     blocking\u001b[39m=\u001b[39;49mblocking,\n\u001b[1;32m   1310\u001b[0m     auto_lfs_prune\u001b[39m=\u001b[39;49mauto_lfs_prune,\n\u001b[1;32m   1311\u001b[0m )\n",
      "File \u001b[0;32m~/miniconda3/envs/DUY/lib/python3.9/site-packages/huggingface_hub/repository.py:1102\u001b[0m, in \u001b[0;36mRepository.git_push\u001b[0;34m(self, upstream, blocking, auto_lfs_prune)\u001b[0m\n\u001b[1;32m   1099\u001b[0m                 \u001b[39mraise\u001b[39;00m subprocess\u001b[39m.\u001b[39mCalledProcessError(return_code, process\u001b[39m.\u001b[39margs, output\u001b[39m=\u001b[39mstdout, stderr\u001b[39m=\u001b[39mstderr)\n\u001b[1;32m   1101\u001b[0m \u001b[39mexcept\u001b[39;00m subprocess\u001b[39m.\u001b[39mCalledProcessError \u001b[39mas\u001b[39;00m exc:\n\u001b[0;32m-> 1102\u001b[0m     \u001b[39mraise\u001b[39;00m \u001b[39mEnvironmentError\u001b[39;00m(exc\u001b[39m.\u001b[39mstderr)\n\u001b[1;32m   1104\u001b[0m \u001b[39mif\u001b[39;00m \u001b[39mnot\u001b[39;00m blocking:\n\u001b[1;32m   1106\u001b[0m     \u001b[39mdef\u001b[39;00m \u001b[39mstatus_method\u001b[39m():\n",
      "\u001b[0;31mOSError\u001b[0m: batch response: Authorization error.\nerror: failed to push some refs to 'https://huggingface.co/DuyTa/whisper-base-vi'\n"
     ]
    }
   ],
   "source": [
    "trainer.push_to_hub(**kwargs)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "DUY",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.17"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
